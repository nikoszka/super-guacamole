2025-11-04 21:40:46 INFO     Finished wandb init.
2025-11-04 21:40:46 INFO     Initializing Llama judge model: Llama-3.1-70B
tokenizer_config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50.5k/50.5k [00:00<00:00, 431kB/s]
tokenizer.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:01<00:00, 7.63MB/s]
special_tokens_map.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 301/301 [00:00<?, ?B/s]
Initializing model:  Llama-3.1-70B and base: meta-llama
Traceback (most recent call last):
  File "C:\Users\nikos\PycharmProjects\nllSAR\src\generate_answers.py", line 275, in <module>
    main(args)
  File "C:\Users\nikos\PycharmProjects\nllSAR\src\generate_answers.py", line 57, in main
    metric = utils.get_metric(args.metric)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nikos\PycharmProjects\nllSAR\src\utils\utils.py", line 394, in get_metric
    metric = get_llama_metric(metric, max_new_tokens=50)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\nikos\PycharmProjects\nllSAR\src\utils\utils.py", line 312, in get_llama_metric
    judge_model = HuggingfaceModel(
                  ^^^^^^^^^^^^^^^^^
  File "C:\Users\nikos\PycharmProjects\nllSAR\src\models\huggingface_models.py", line 157, in __init__
    raise ValueError
ValueError

_wandb:
    value:
        cli_version: 0.22.3
        e:
            l3wbondqbtcz6dhoyavwu2k6x8nb533x:
                args:
                    - --eval_wandb_runid
                    - 5qvhbs97
                    - --metric
                    - llm_llama-3.1-70b
                    - --recompute_accuracy
                    - --no-compute_predictive_entropy
                    - --no-compute_p_ik
                    - --no-compute_context_entails_response
                    - --no-analyze_run
                    - --entity
                    - nikosteam
                    - --project
                    - super_guacamole
                    - --restore_entity_eval
                    - nikosteam
                codePath: src/compute_uncertainty_measures.py
                codePathLocal: compute_uncertainty_measures.py
                cpu_count: 24
                cpu_count_logical: 48
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "200492560384"
                        used: "16734695424"
                email: nikosz@hotmail.sk
                executable: /system/user/studentwork/boldis/nllSAR/bin/python
                git:
                    commit: 0bb266b78307c42c23c4b1b891d70d8726b25c6c
                    remote: git@github.com:nikoszka/super-guacamole.git
                gpu: NVIDIA TITAN V
                gpu_count: 4
                gpu_nvidia:
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-38c9f8cb-6f53-580c-e483-28ee83a55b2f
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-e47fc508-4725-3969-157c-8cb2214b1d31
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-3b65c462-039a-c95a-b94b-8c380fc4887d
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-b79bba9d-bc83-74d1-aa8c-33e0625285b7
                host: student02
                memory:
                    total: "403759579136"
                os: Linux-5.14.0-570.55.1.el9_6.x86_64-x86_64-with-glibc2.34
                program: /system/user/studentwork/boldis/super-guacamole/src/compute_uncertainty_measures.py
                python: CPython 3.11.14
                root: ./boldis/uncertainty/wandb
                startedAt: "2025-11-23T17:38:29.574370Z"
                writerId: l3wbondqbtcz6dhoyavwu2k6x8nb533x
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "3":
                - 16
            "4": 3.11.14
            "5": 0.22.3
            "6": 4.57.1
            "12": 0.22.3
            "13": linux-x86_64
analyze_run:
    value: false
answerable_only:
    value: true
assign_new_wandb_id:
    value: true
brief_always:
    value: false
brief_prompt:
    value: manual
compute_accuracy_at_all_temps:
    value: true
compute_context_entails_response:
    value: false
compute_p_ik:
    value: false
compute_p_ik_answerable:
    value: false
compute_p_true:
    value: false
compute_p_true_in_compute_stage:
    value: false
compute_predictive_entropy:
    value: false
compute_uncertainties:
    value: false
condition_on_question:
    value: true
dataset:
    value: trivia_qa
debug:
    value: false
enable_brief:
    value: true
entailment_cache_id:
    value: null
entailment_cache_only:
    value: false
entailment_model:
    value: deberta
entity:
    value: nikosteam
eval_wandb_runid:
    value: 5qvhbs97
experiment_lot:
    value: Unnamed Experiment
get_training_set_generations:
    value: true
get_training_set_generations_most_likely_only:
    value: true
is_ood_eval:
    value: false
metric:
    value: llm_llama-3.1-70b
model_max_new_tokens:
    value: 100
model_name:
    value: Llama-3.2-1B
num_eval_samples:
    value: 1e+19
num_few_shot:
    value: 0
num_generations:
    value: 1
num_samples:
    value: 400
ood_train_dataset:
    value: null
p_true_hint:
    value: false
p_true_num_fewshot:
    value: 20
project:
    value: super_guacamole
prompt_type:
    value: default
random_seed:
    value: 10
recompute_accuracy:
    value: true
restore_entity_eval:
    value: nikosteam
restore_entity_train:
    value: null
reuse_entailment_model:
    value: false
strict_entailment:
    value: true
temperature:
    value: 0
train_wandb_runid:
    value: 5qvhbs97
use_all_generations:
    value: true
use_context:
    value: false
use_mc_options:
    value: true
use_num_generations:
    value: -1

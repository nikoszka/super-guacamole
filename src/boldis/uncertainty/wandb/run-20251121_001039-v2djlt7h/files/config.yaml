_wandb:
    value:
        cli_version: 0.22.3
        e:
            o0avdzcp9ajlbfikbd6ckx0afbrfkxp6:
                args:
                    - --model_name
                    - Llama-3.1-8B-Instruct
                    - --dataset
                    - trivia_qa
                    - --num_samples
                    - "50"
                    - --num_generations
                    - "1"
                    - --temperature
                    - "0.0"
                    - --model_max_new_tokens
                    - "200"
                    - --num_few_shot
                    - "5"
                    - --brief_prompt
                    - detailed
                    - --enable_brief
                    - --use_context
                    - --answerable_only
                    - --get_training_set_generations
                    - --no-compute_p_true
                    - --no-compute_uncertainties
                    - --entity
                    - nikosteam
                    - --project
                    - super_guacamole
                    - --experiment_lot
                    - long_answers_token_tracking_20251121_001019
                codePath: src/generate_answers.py
                codePathLocal: generate_answers.py
                cpu_count: 24
                cpu_count_logical: 48
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "200492560384"
                        used: "16552947712"
                email: nikosz@hotmail.sk
                executable: /system/user/studentwork/boldis/nllSAR/bin/python
                git:
                    commit: 3ca18cdfe3e83e68cf44e200890c15d68c782a6c
                    remote: git@github.com:nikoszka/super-guacamole.git
                gpu: NVIDIA TITAN V
                gpu_count: 4
                gpu_nvidia:
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-38c9f8cb-6f53-580c-e483-28ee83a55b2f
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-e47fc508-4725-3969-157c-8cb2214b1d31
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-3b65c462-039a-c95a-b94b-8c380fc4887d
                    - architecture: Volta
                      cudaCores: 5120
                      memoryTotal: "12884901888"
                      name: NVIDIA TITAN V
                      uuid: GPU-b79bba9d-bc83-74d1-aa8c-33e0625285b7
                host: student02
                memory:
                    total: "403759579136"
                os: Linux-5.14.0-570.55.1.el9_6.x86_64-x86_64-with-glibc2.34
                program: /system/user/studentwork/boldis/super-guacamole/src/generate_answers.py
                python: CPython 3.11.14
                root: ./boldis/uncertainty
                startedAt: "2025-11-20T23:10:39.343600Z"
                writerId: o0avdzcp9ajlbfikbd6ckx0afbrfkxp6
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "3":
                - 16
            "4": 3.11.14
            "5": 0.22.3
            "6": 4.57.1
            "12": 0.22.3
            "13": linux-x86_64
analyze_run:
    value: true
answerable_only:
    value: true
assign_new_wandb_id:
    value: true
brief_always:
    value: false
brief_prompt:
    value: detailed
compute_accuracy_at_all_temps:
    value: true
compute_context_entails_response:
    value: false
compute_p_ik:
    value: true
compute_p_ik_answerable:
    value: false
compute_p_true:
    value: false
compute_p_true_in_compute_stage:
    value: false
compute_predictive_entropy:
    value: true
compute_uncertainties:
    value: false
condition_on_question:
    value: true
dataset:
    value: trivia_qa
debug:
    value: false
enable_brief:
    value: true
entailment_cache_id:
    value: null
entailment_cache_only:
    value: false
entailment_model:
    value: deberta
entity:
    value: nikosteam
eval_wandb_runid:
    value: null
experiment_lot:
    value: long_answers_token_tracking_20251121_001019
get_training_set_generations:
    value: true
get_training_set_generations_most_likely_only:
    value: true
metric:
    value: squad
model_max_new_tokens:
    value: 200
model_name:
    value: Llama-3.1-8B-Instruct
num_eval_samples:
    value: 1e+19
num_few_shot:
    value: 5
num_generations:
    value: 1
num_samples:
    value: 50
ood_train_dataset:
    value: null
p_true_hint:
    value: false
p_true_num_fewshot:
    value: 20
project:
    value: super_guacamole
prompt_type:
    value: default
random_seed:
    value: 10
recompute_accuracy:
    value: false
restore_entity_eval:
    value: null
restore_entity_train:
    value: null
reuse_entailment_model:
    value: false
strict_entailment:
    value: true
temperature:
    value: 0
train_wandb_runid:
    value: null
use_all_generations:
    value: true
use_context:
    value: true
use_mc_options:
    value: true
use_num_generations:
    value: -1

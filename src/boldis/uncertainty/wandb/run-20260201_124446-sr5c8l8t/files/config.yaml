_wandb:
    value:
        cli_version: 0.22.3
        e:
            0qni3fmz0o79mmwqjn8n2b540nv45o73:
                args:
                    - --model_name
                    - Llama-3.1-70B-Instruct-4bit
                    - --dataset
                    - trivia_qa
                    - --num_samples
                    - "400"
                    - --num_few_shot
                    - "5"
                    - --temperature
                    - "0.0"
                    - --num_generations
                    - "1"
                    - --brief_prompt
                    - short
                    - --enable_brief
                    - --brief_always
                    - --no-compute_uncertainties
                    - --no-compute_p_true
                    - --no-get_training_set_generations
                    - --use_context
                    - --entity
                    - nikosteam
                    - --project
                    - super_guacamole
                    - --experiment_lot
                    - ultra_large_Llama_XLarge_trivia_qa_20260201_124422
                codePath: src/generate_answers.py
                codePathLocal: generate_answers.py
                cpu_count: 6
                cpu_count_logical: 12
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "144208859136"
                        used: "15367168000"
                email: nikosz@hotmail.sk
                executable: /system/user/studentwork/boldis/nllSAR/bin/python
                git:
                    commit: d83b45b0da43cea4e06a994fd0fd8caf7ffef8fa
                    remote: git@github.com:nikoszka/super-guacamole.git
                gpu: NVIDIA GeForce GTX 1080 Ti
                gpu_count: 4
                gpu_nvidia:
                    - architecture: Pascal
                      cudaCores: 3584
                      memoryTotal: "11811160064"
                      name: NVIDIA GeForce GTX 1080 Ti
                      uuid: GPU-d9c5fed3-cb5b-a851-7956-c16fb36d2249
                    - architecture: Pascal
                      cudaCores: 3584
                      memoryTotal: "11811160064"
                      name: NVIDIA GeForce GTX 1080 Ti
                      uuid: GPU-c226cb77-a30d-4960-a433-c287ef9b66bb
                    - architecture: Pascal
                      cudaCores: 3584
                      memoryTotal: "11811160064"
                      name: NVIDIA GeForce GTX 1080 Ti
                      uuid: GPU-352fd5d3-bbea-6939-14b8-5113586e7936
                    - architecture: Pascal
                      cudaCores: 3584
                      memoryTotal: "11811160064"
                      name: NVIDIA GeForce GTX 1080 Ti
                      uuid: GPU-0cefea6d-fdf1-ba03-6451-057a717a9977
                host: student01
                memory:
                    total: "66789847040"
                os: Linux-5.14.0-611.9.1.el9_7.x86_64-x86_64-with-glibc2.34
                program: /system/user/studentwork/boldis/super-guacamole/src/generate_answers.py
                python: CPython 3.11.14
                root: ./boldis/uncertainty
                startedAt: "2026-02-01T11:44:46.912176Z"
                writerId: 0qni3fmz0o79mmwqjn8n2b540nv45o73
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "2":
                - 1
                - 5
                - 11
                - 41
                - 49
                - 51
                - 53
                - 71
                - 95
                - 100
            "3":
                - 16
            "4": 3.11.14
            "5": 0.22.3
            "6": 4.57.1
            "12": 0.22.3
            "13": linux-x86_64
analyze_run:
    value: true
answerable_only:
    value: false
assign_new_wandb_id:
    value: true
brief_always:
    value: true
brief_prompt:
    value: short
compute_accuracy_at_all_temps:
    value: true
compute_context_entails_response:
    value: false
compute_p_ik:
    value: true
compute_p_ik_answerable:
    value: false
compute_p_true:
    value: false
compute_p_true_in_compute_stage:
    value: false
compute_predictive_entropy:
    value: true
compute_uncertainties:
    value: false
condition_on_question:
    value: true
dataset:
    value: trivia_qa
debug:
    value: false
enable_brief:
    value: true
entailment_cache_id:
    value: null
entailment_cache_only:
    value: false
entailment_model:
    value: deberta
entity:
    value: nikosteam
eval_wandb_runid:
    value: null
experiment_lot:
    value: ultra_large_Llama_XLarge_trivia_qa_20260201_124422
get_training_set_generations:
    value: false
get_training_set_generations_most_likely_only:
    value: true
metric:
    value: squad
model_max_new_tokens:
    value: 150
model_name:
    value: Llama-3.1-70B-Instruct-4bit
num_eval_samples:
    value: 1e+19
num_few_shot:
    value: 5
num_generations:
    value: 1
num_samples:
    value: 400
ood_train_dataset:
    value: null
p_true_hint:
    value: false
p_true_num_fewshot:
    value: 20
project:
    value: super_guacamole
prompt_type:
    value: default
random_seed:
    value: 10
recompute_accuracy:
    value: false
restore_entity_eval:
    value: null
restore_entity_train:
    value: null
reuse_entailment_model:
    value: false
strict_entailment:
    value: true
temperature:
    value: 0
train_wandb_runid:
    value: null
use_all_generations:
    value: true
use_context:
    value: true
use_mc_options:
    value: true
use_num_generations:
    value: -1

# ğŸš€ Quick Start: Generate & Analyze

## Step 1: Generate Short Answers (15-30 min)

```bash
python -m src.generate_answers \
  --model_name Llama-3.2-1B \
  --dataset trivia_qa \
  --num_samples 200 \
  --num_generations 1 \
  --temperature 0.0 \
  --model_max_new_tokens 50 \
  --brief_prompt short \
  --metric squad \
  --use_context False \
  --compute_p_true False \
  --entity nikosteam \
  --project nllSAR_short
```

**Output:** `src/nikos/uncertainty/wandb/run-XXXXX/files/validation_generations.pkl`

---

## Step 2: Generate Long Answers (30-60 min)

```bash
python -m src.generate_answers \
  --model_name Llama-3.2-1B \
  --dataset trivia_qa \
  --num_samples 200 \
  --num_generations 1 \
  --temperature 0.0 \
  --model_max_new_tokens 200 \
  --brief_prompt detailed \
  --metric llm_llama-3.1-70b \
  --use_context True \
  --compute_p_true False \
  --entity nikosteam \
  --project nllSAR_long
```

**Output:** Another `validation_generations.pkl` in a new wandb run directory

---

## Step 3: Run Analysis Pipeline

### A. Phase 1: Baseline Metrics

**Short:**
```bash
python -m src.analysis.phase1_baseline_metrics \
  --short-pickle PATH_TO_SHORT_PKL \
  --output-dir results/phase1_short
```

**Long:**
```bash
python -m src.analysis.phase1_baseline_metrics \
  --long-pickle PATH_TO_LONG_PKL \
  --output-dir results/phase1_long
```

---

### B. Phase 1.5: Token-Level NLL Analysis

**Long answers:**
```bash
python -m src.analysis.phase1_5_token_nll_analysis \
  --pickle-path PATH_TO_LONG_PKL \
  --model-name Llama-3.2-1B \
  --sample-size 100 \
  --output-dir results/phase1_5_long
```

**Short answers:**
```bash
python -m src.analysis.phase1_5_token_nll_analysis \
  --pickle-path PATH_TO_SHORT_PKL \
  --model-name Llama-3.2-1B \
  --sample-size 100 \
  --output-dir results/phase1_5_short
```

---

### C. Phase 1.6: Prefix-Level NLL

**Long (LLM judge):**
```bash
python -m src.analysis.phase1_6_prefix_nll_analysis \
  --pickle-path PATH_TO_LONG_PKL \
  --output-dir results/phase1_6_long \
  --max-prefix-len 50 \
  --ks 1 3 5
```

**Short (ROUGE):**
```bash
python -m src.analysis.phase1_6_prefix_nll_analysis \
  --pickle-path PATH_TO_SHORT_PKL \
  --output-dir results/phase1_6_short \
  --use-rouge \
  --rouge-threshold 0.3 \
  --max-prefix-len 50 \
  --ks 1 3 5
```

---

### D. Phase 2: Token Relevance (SAR-style)

```bash
python -m src.analysis.phase2_token_importance \
  --pickle-path PATH_TO_LONG_PKL \
  --model-name Llama-3.2-1B \
  --similarity-model cross-encoder/stsb-roberta-large \
  --sample-size 50 \
  --output-dir results/phase2_long
```

---

### E. Phase 5: Comparative AUROC Analysis

**Long answers:**
```bash
python -m src.analysis.phase5_comparative_analysis \
  --pickle-path PATH_TO_LONG_PKL \
  --model-name Llama-3.2-1B \
  --similarity-model cross-encoder/stsb-roberta-large \
  --output-dir results/phase5_long
```

**Short answers (ROUGE-based):**
```bash
python -m src.analysis.phase5_comparative_analysis \
  --pickle-path PATH_TO_SHORT_PKL \
  --model-name Llama-3.2-1B \
  --similarity-model cross-encoder/stsb-roberta-large \
  --output-dir results/phase5_short \
  --use-rouge \
  --rouge-threshold 0.3
```

---

## Step 4: Visualize Results

```bash
streamlit run src/analysis/token_visualization_app.py
```

**In the browser:**
- Mode: "Raw NLL (Phase 1.5)" â†’ Load `results/phase1_5_long/sentence_level_nll_examples.json`
- Mode: "Relevance-weighted (Phase 2)" â†’ Load `results/phase2_long/token_importance_examples.json`

---

## ğŸ“ File Locations Cheat Sheet

### After Generation:
```
src/nikos/uncertainty/wandb/
â””â”€â”€ run-<TIMESTAMP>-<ID>/
    â””â”€â”€ files/
        â”œâ”€â”€ validation_generations.pkl    â† Use this for analysis
        â”œâ”€â”€ train_generations.pkl
        â””â”€â”€ experiment_details.pkl
```

### After Analysis:
```
results/
â”œâ”€â”€ phase1_short/
â”‚   â”œâ”€â”€ token_statistics.json
â”‚   â”œâ”€â”€ baseline_metrics_short.csv
â”‚   â””â”€â”€ baseline_metrics.json
â”œâ”€â”€ phase1_5_long/
â”‚   â”œâ”€â”€ nll_vs_position.png
â”‚   â”œâ”€â”€ nll_distribution.png
â”‚   â””â”€â”€ sentence_level_nll_examples.json
â”œâ”€â”€ phase2_long/
â”‚   â”œâ”€â”€ relevance_vs_position.png
â”‚   â””â”€â”€ token_importance_examples.json
â””â”€â”€ phase5_long/
    â”œâ”€â”€ auroc_comparison.csv
    â”œâ”€â”€ roc_curves.png
    â””â”€â”€ cost_performance_plot.png
```

---

## âœ… Verify Your Pickle

Before running analysis, verify the new pickle structure:

```python
import pickle

# Load your pickle
with open('PATH_TO_YOUR_PICKLE', 'rb') as f:
    data = pickle.load(f)

# Get first example
example = list(data.values())[0]
mla = example['most_likely_answer']

# Verify new fields exist
print("âœ… Has token_ids:", 'token_ids' in mla)
print("âœ… Has tokens:", 'tokens' in mla)
print("âœ… Token count:", len(mla.get('tokens', [])))
print("âœ… Log-lik count:", len(mla.get('token_log_likelihoods', [])))
print("âœ… Match:", len(mla.get('tokens', [])) == len(mla.get('token_log_likelihoods', [])))

# Show sample
print("\nFirst 5 tokens:", mla.get('tokens', [])[:5])
print("First 5 log-liks:", mla.get('token_log_likelihoods', [])[:5])
```

Expected output:
```
âœ… Has token_ids: True
âœ… Has tokens: True
âœ… Token count: 45
âœ… Log-lik count: 45
âœ… Match: True

First 5 tokens: [' The', ' Battle', ' of', ' Hast', 'ings']
First 5 log-liks: [-0.234, -0.156, -0.089, -0.445, -0.234]
```

---

## ğŸ¯ What Changed? (Quick Version)

### Before (Old Pickles)
```python
most_likely_answer = {
    'response': "The Battle of Hastings",
    'token_log_likelihoods': [-0.234, -0.156, ...]
}
# âŒ No tokens stored â†’ Analysis re-tokenizes â†’ Mismatches!
```

### After (New Pickles)
```python
most_likely_answer = {
    'response': "The Battle of Hastings",
    'token_ids': [450, 11045, 315, 19826, 826],        # NEW!
    'tokens': [' The', ' Battle', ' of', ' Hast', 'ings'],  # NEW!
    'token_log_likelihoods': [-0.234, -0.156, -0.089, -0.445, -0.234]
}
# âœ… Exact tokens stored â†’ Analysis uses them â†’ Perfect alignment!
```

---

## ğŸ› Common Issues

### "Token count mismatch" warnings
â†’ Using old pickle. Re-generate with updated code.

### "No module named 'transformers'"
â†’ Install: `pip install transformers accelerate`

### "CUDA out of memory"
â†’ Reduce `--num_samples` or use smaller model

### "KeyError: 'token_ids'"
â†’ Old pickle + outdated analysis script. Pull latest code.

---

## ğŸ“Š Expected Analysis Coverage

| Phase | Old Pickles | New Pickles |
|-------|-------------|-------------|
| Phase 1 | âœ… Works | âœ… Works |
| Phase 1.5 | âŒ 35% success | âœ… 100% success |
| Phase 1.6 | âœ… Works | âœ… Works |
| Phase 2 | âŒ ~40% success | âœ… 100% success |
| Phase 5 (baselines) | âœ… Works | âœ… Works |
| Phase 5 (SAR/SE) | âŒ Need multi-samples | âœ… Works with temp=1.0 |

---

## ğŸ“š More Documentation

- **Detailed changes**: `CHANGES_SUMMARY.md`
- **Generation settings guide**: `GENERATION_SETTINGS_GUIDE.md`
- **Full analysis pipeline**: `ANALYSIS_README.md`

---

## ğŸ’¡ Pro Tips

1. **Start small**: Use `--num_samples 50` for testing
2. **Use ROUGE for speed**: `--metric squad` is much faster than LLM judges
3. **Greedy first**: Always start with `--num_generations 1 --temperature 0.0` for baseline
4. **Few-shot helps**: Keep `--num_few_shot 5` (improves quality, unrelated to temperature)
5. **GPU memory**: Monitor with `nvidia-smi` during generation
6. **Intermediate saves**: Wandb auto-saves, check wandb run folder periodically
7. **Analysis order**: Run Phase 1 â†’ 1.5 â†’ 1.6 â†’ 2 â†’ 5 in sequence

---

## ğŸ‰ You're Ready!

1. Generate pickles (Steps 1-2) âœ…
2. Run all analysis phases (Step 3) âœ…
3. Visualize with Streamlit (Step 4) âœ…
4. Enjoy your comprehensive uncertainty analysis! ğŸŠ

